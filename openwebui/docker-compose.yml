services:
  postgres:
    image: pgvector/pgvector:pg17
    container_name: pgvector
    environment:
      POSTGRES_DB: postgres
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
      TZ: Asia/Taipei
    volumes:
      - ./pgdata:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres -d postgres"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped

  redis:
    image: redis:7-alpine
    container_name: redis
    ports:
      - "6379:6379"
    volumes:
      - ./redis-data:/data
    command: redis-server --appendonly yes
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  tika:
    image: apache/tika:latest-full
    container_name: tika
    ports:
      - "9998:9998"
    restart: unless-stopped

  openwebui:
    image: ghcr.io/open-webui/open-webui:cuda
    container_name: openwebui
    environment:
      - DB_TYPE=postgresql
      - DB_HOST=pgvector
      - DB_PORT=5432
      - DB_NAME=postgres
      - DB_USER=postgres
      - DB_PASSWORD=postgres
      - OLLAMA_BASE_URL=http://192.168.20.12:11434
      - PIPELINE_URL=http://pipelines:9099
      - ENABLE_RAG_WEB_SEARCH=True
      - RAG_WEB_SEARCH_ENGINE=searxng
      - RAG_WEB_SEARCH_RESULT_COUNT=3
      - RAG_WEB_SEARCH_CONCURRENT_REQUESTS=10
      - SEARXNG_QUERY_URL=http://192.168.25.12:8080/search?q=<query>
    env_file:
      - .env
    ports:
      - "16888:8080"
    volumes:
      - ./openwebui-data:/app/backend/data
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_started
    restart: unless-stopped

  pipelines:
    image: ghcr.io/open-webui/pipelines:main
    container_name: pipelines
    ports:
      - "9099:9099"
    environment:
      PIPELINES_URLS: "https://github.com/open-webui/pipelines/blob/main/examples/filters/detoxify_filter_pipeline.py"
    volumes:
      - ./pipelines:/app/pipelines
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9099/"]
      interval: 10s
      timeout: 5s
      retries: 3
    restart: always

  sd-webui:
    image: ghcr.io/neggles/sd-webui-docker:latest
    container_name: automatic1111
    environment:
      SD_WEBUI_VARIANT: "automatic1111"
      CLI_ARGS: "--allow-code --enable-insecure-extension-access --api --opt-channelslast --opt-sdp-attention"
      PYTORCH_CUDA_ALLOC_CONF: "garbage_collection_threshold:0.9,max_split_size_mb:512"
      CUDA_MODULE_LOADING: "LAZY"
      SAFETENSORS_FAST_GPU: "1"
      NUMEXPR_MAX_THREADS: "16"
      TORCH_CUDNN_V8_API_ENABLED: "1"
      TORCH_ALLOW_TF32_CUBLAS_OVERRIDE: "1"
      USE_EXPERIMENTAL_CUDNN_V8_API: "1"
    ipc: host
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              capabilities: [ gpu ]
              device_ids: [ "3" ]
    ports:
      - "7860:7860"
    volumes:
      - ./stable-diffusion-webui/sd-models:/data/models
      - ./stable-diffusion-webui/sd-outputs:/data/outputs
    restart: unless-stopped


  docling-serve:
    image: quay.io/docling-project/docling-serve-cu124
    container_name: Docling
    ports:
      - "5001:5001"
    environment:
      - DOCLING_SERVE_ENABLE_UI=true
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              capabilities: [gpu]
              device_ids: [ "2" ]
 
  watchtower:
    image: containrrr/watchtower
    container_name: watchtower
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    command: --interval 86400 openwebui
    depends_on:
      - openwebui
    restart: unless-stopped

networks:
  default:
    name: webui-net

